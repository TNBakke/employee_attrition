{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=16)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=4000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/clean_one_hot_data.csv\")\n",
    "df.drop(df.columns[0], axis=1,inplace=True)\n",
    "\n",
    "y = df['attrition']\n",
    "X = df.drop(columns=['attrition'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=4000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305  15  29  19]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(confusion_matrix)\n",
    "# from documentation: tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assumed_top_10 = ['age', 'job_satisfaction', 'monthly_income', 'over_time', 'work_life_balance', 'years_since_last_promotion', \n",
    "                  'marital_status_single', 'department_sales', 'num_companies_worked', 'job_involvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assumed_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4463504 ,  2.28090588, -0.16239918, ..., -0.31409347,\n",
       "        -0.91892141,  1.45864991],\n",
       "       [ 1.32236521, -0.4384223 ,  1.71733935, ..., -0.31409347,\n",
       "         1.08823234, -0.68556546],\n",
       "       [ 0.008343  ,  2.28090588, -0.16239918, ..., -0.31409347,\n",
       "        -0.91892141,  1.45864991],\n",
       "       ...,\n",
       "       [-1.08667552, -0.4384223 , -0.16239918, ..., -0.31409347,\n",
       "         1.08823234, -0.68556546],\n",
       "       [ 1.32236521, -0.4384223 ,  1.71733935, ..., -0.31409347,\n",
       "         1.08823234, -0.68556546],\n",
       "       [-0.32016256, -0.4384223 , -0.16239918, ..., -0.31409347,\n",
       "         1.08823234, -0.68556546]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/clean_one_hot_data.csv\")\n",
    "df.drop(df.columns[0], axis=1,inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['attrition']\n",
    "X = df[assumed_top_10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=4000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=4000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function confusion_matrix at 0x7f0dc35c6710>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "con_matrix = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(confusion_matrix)\n",
    "# from documentation: tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coeffs = ['daily_rate', 'monthly_income', 'job_satisfaction', 'business_travel', 'years_at_company', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=150)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/clean_one_hot_data.csv\")\n",
    "df.drop(df.columns[0], axis=1,inplace=True)\n",
    "\n",
    "y = df['attrition']\n",
    "X = df[lasso_coeffs]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=150)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.86957\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict_proba(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320   0  48   0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_new = pd.Series(y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred_new).ravel()\n",
    "print(cm)\n",
    "# from documentation: tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78165809 0.21834191]\n",
      " [0.83391964 0.16608036]\n",
      " [0.69467028 0.30532972]\n",
      " [0.84745935 0.15254065]\n",
      " [0.88358269 0.11641731]\n",
      " [0.81367753 0.18632247]\n",
      " [0.81253745 0.18746255]\n",
      " [0.83324134 0.16675866]\n",
      " [0.97786379 0.02213621]\n",
      " [0.83393212 0.16606788]\n",
      " [0.89452446 0.10547554]\n",
      " [0.96069353 0.03930647]\n",
      " [0.84341695 0.15658305]\n",
      " [0.85377487 0.14622513]\n",
      " [0.74558474 0.25441526]\n",
      " [0.67539433 0.32460567]\n",
      " [0.69424574 0.30575426]\n",
      " [0.83569386 0.16430614]\n",
      " [0.95539914 0.04460086]\n",
      " [0.86457395 0.13542605]\n",
      " [0.61793877 0.38206123]\n",
      " [0.9055103  0.0944897 ]\n",
      " [0.8863323  0.1136677 ]\n",
      " [0.79248488 0.20751512]\n",
      " [0.76675727 0.23324273]\n",
      " [0.99285571 0.00714429]\n",
      " [0.73838661 0.26161339]\n",
      " [0.76897054 0.23102946]\n",
      " [0.84332882 0.15667118]\n",
      " [0.80825714 0.19174286]\n",
      " [0.82465559 0.17534441]\n",
      " [0.87179568 0.12820432]\n",
      " [0.73374326 0.26625674]\n",
      " [0.89953191 0.10046809]\n",
      " [0.78484971 0.21515029]\n",
      " [0.9147445  0.0852555 ]\n",
      " [0.94695544 0.05304456]\n",
      " [0.82883218 0.17116782]\n",
      " [0.79778489 0.20221511]\n",
      " [0.71053891 0.28946109]\n",
      " [0.91520037 0.08479963]\n",
      " [0.83273048 0.16726952]\n",
      " [0.85767862 0.14232138]\n",
      " [0.71172975 0.28827025]\n",
      " [0.76319843 0.23680157]\n",
      " [0.9470638  0.0529362 ]\n",
      " [0.85123928 0.14876072]\n",
      " [0.7132842  0.2867158 ]\n",
      " [0.81142248 0.18857752]\n",
      " [0.76045725 0.23954275]\n",
      " [0.9452438  0.0547562 ]\n",
      " [0.85465164 0.14534836]\n",
      " [0.97876671 0.02123329]\n",
      " [0.80408771 0.19591229]\n",
      " [0.80654236 0.19345764]\n",
      " [0.77283997 0.22716003]\n",
      " [0.87949402 0.12050598]\n",
      " [0.79670686 0.20329314]\n",
      " [0.8537135  0.1462865 ]\n",
      " [0.78910105 0.21089895]\n",
      " [0.89431979 0.10568021]\n",
      " [0.6203319  0.3796681 ]\n",
      " [0.77905947 0.22094053]\n",
      " [0.9483857  0.0516143 ]\n",
      " [0.79336927 0.20663073]\n",
      " [0.81649761 0.18350239]\n",
      " [0.82142956 0.17857044]\n",
      " [0.76433654 0.23566346]\n",
      " [0.84256219 0.15743781]\n",
      " [0.97489894 0.02510106]\n",
      " [0.79224255 0.20775745]\n",
      " [0.91130207 0.08869793]\n",
      " [0.87111077 0.12888923]\n",
      " [0.83183603 0.16816397]\n",
      " [0.88507831 0.11492169]\n",
      " [0.9480363  0.0519637 ]\n",
      " [0.79398463 0.20601537]\n",
      " [0.77589109 0.22410891]\n",
      " [0.83123659 0.16876341]\n",
      " [0.84802475 0.15197525]\n",
      " [0.96501162 0.03498838]\n",
      " [0.83562933 0.16437067]\n",
      " [0.96133239 0.03866761]\n",
      " [0.77811527 0.22188473]\n",
      " [0.80221056 0.19778944]\n",
      " [0.91848722 0.08151278]\n",
      " [0.87227639 0.12772361]\n",
      " [0.86939462 0.13060538]\n",
      " [0.82762318 0.17237682]\n",
      " [0.80241752 0.19758248]\n",
      " [0.87603906 0.12396094]\n",
      " [0.72123454 0.27876546]\n",
      " [0.92122813 0.07877187]\n",
      " [0.68813022 0.31186978]\n",
      " [0.90254742 0.09745258]\n",
      " [0.91256934 0.08743066]\n",
      " [0.89255525 0.10744475]\n",
      " [0.93908121 0.06091879]\n",
      " [0.86892701 0.13107299]\n",
      " [0.92179944 0.07820056]\n",
      " [0.98394254 0.01605746]\n",
      " [0.84098691 0.15901309]\n",
      " [0.93904821 0.06095179]\n",
      " [0.80907714 0.19092286]\n",
      " [0.95413026 0.04586974]\n",
      " [0.89615561 0.10384439]\n",
      " [0.92233431 0.07766569]\n",
      " [0.74340099 0.25659901]\n",
      " [0.90636734 0.09363266]\n",
      " [0.98184186 0.01815814]\n",
      " [0.85728322 0.14271678]\n",
      " [0.85525324 0.14474676]\n",
      " [0.93119519 0.06880481]\n",
      " [0.82518042 0.17481958]\n",
      " [0.74710873 0.25289127]\n",
      " [0.9011543  0.0988457 ]\n",
      " [0.85011705 0.14988295]\n",
      " [0.85369832 0.14630168]\n",
      " [0.94947481 0.05052519]\n",
      " [0.794813   0.205187  ]\n",
      " [0.81816209 0.18183791]\n",
      " [0.91402719 0.08597281]\n",
      " [0.80581953 0.19418047]\n",
      " [0.96120546 0.03879454]\n",
      " [0.74234724 0.25765276]\n",
      " [0.74403673 0.25596327]\n",
      " [0.84913076 0.15086924]\n",
      " [0.91699315 0.08300685]\n",
      " [0.91359815 0.08640185]\n",
      " [0.8770816  0.1229184 ]\n",
      " [0.78276721 0.21723279]\n",
      " [0.81807782 0.18192218]\n",
      " [0.91304349 0.08695651]\n",
      " [0.79286146 0.20713854]\n",
      " [0.87091498 0.12908502]\n",
      " [0.84586013 0.15413987]\n",
      " [0.75589768 0.24410232]\n",
      " [0.74139278 0.25860722]\n",
      " [0.82116196 0.17883804]\n",
      " [0.95573945 0.04426055]\n",
      " [0.64759662 0.35240338]\n",
      " [0.84135274 0.15864726]\n",
      " [0.89980097 0.10019903]\n",
      " [0.79405403 0.20594597]\n",
      " [0.95622917 0.04377083]\n",
      " [0.87330371 0.12669629]\n",
      " [0.81739249 0.18260751]\n",
      " [0.56281558 0.43718442]\n",
      " [0.68403592 0.31596408]\n",
      " [0.8010894  0.1989106 ]\n",
      " [0.88375109 0.11624891]\n",
      " [0.92872946 0.07127054]\n",
      " [0.81750214 0.18249786]\n",
      " [0.79258919 0.20741081]\n",
      " [0.90446384 0.09553616]\n",
      " [0.66617458 0.33382542]\n",
      " [0.86506935 0.13493065]\n",
      " [0.77037554 0.22962446]\n",
      " [0.95465934 0.04534066]\n",
      " [0.79476553 0.20523447]\n",
      " [0.81952056 0.18047944]\n",
      " [0.88358088 0.11641912]\n",
      " [0.93401608 0.06598392]\n",
      " [0.75837941 0.24162059]\n",
      " [0.91377799 0.08622201]\n",
      " [0.84787324 0.15212676]\n",
      " [0.80567533 0.19432467]\n",
      " [0.85772769 0.14227231]\n",
      " [0.98275918 0.01724082]\n",
      " [0.90740214 0.09259786]\n",
      " [0.81961485 0.18038515]\n",
      " [0.94874444 0.05125556]\n",
      " [0.81827007 0.18172993]\n",
      " [0.71588698 0.28411302]\n",
      " [0.87873876 0.12126124]\n",
      " [0.86615369 0.13384631]\n",
      " [0.86989252 0.13010748]\n",
      " [0.93666664 0.06333336]\n",
      " [0.95366408 0.04633592]\n",
      " [0.71371587 0.28628413]\n",
      " [0.96659062 0.03340938]\n",
      " [0.8502795  0.1497205 ]\n",
      " [0.97983626 0.02016374]\n",
      " [0.84525363 0.15474637]\n",
      " [0.88355811 0.11644189]\n",
      " [0.85462124 0.14537876]\n",
      " [0.89379366 0.10620634]\n",
      " [0.93724419 0.06275581]\n",
      " [0.88742565 0.11257435]\n",
      " [0.82422913 0.17577087]\n",
      " [0.90338718 0.09661282]\n",
      " [0.94692025 0.05307975]\n",
      " [0.7996996  0.2003004 ]\n",
      " [0.78410544 0.21589456]\n",
      " [0.82719223 0.17280777]\n",
      " [0.87327056 0.12672944]\n",
      " [0.8057602  0.1942398 ]\n",
      " [0.96459927 0.03540073]\n",
      " [0.89375562 0.10624438]\n",
      " [0.8545697  0.1454303 ]\n",
      " [0.91136856 0.08863144]\n",
      " [0.79733669 0.20266331]\n",
      " [0.70713901 0.29286099]\n",
      " [0.97246783 0.02753217]\n",
      " [0.94719237 0.05280763]\n",
      " [0.81947121 0.18052879]\n",
      " [0.74301649 0.25698351]\n",
      " [0.9016577  0.0983423 ]\n",
      " [0.84380772 0.15619228]\n",
      " [0.98098876 0.01901124]\n",
      " [0.91984901 0.08015099]\n",
      " [0.63922758 0.36077242]\n",
      " [0.8148355  0.1851645 ]\n",
      " [0.79228569 0.20771431]\n",
      " [0.89589288 0.10410712]\n",
      " [0.92944831 0.07055169]\n",
      " [0.92419546 0.07580454]\n",
      " [0.91012727 0.08987273]\n",
      " [0.7091047  0.2908953 ]\n",
      " [0.92254716 0.07745284]\n",
      " [0.8692174  0.1307826 ]\n",
      " [0.68234619 0.31765381]\n",
      " [0.96094427 0.03905573]\n",
      " [0.63571406 0.36428594]\n",
      " [0.77257782 0.22742218]\n",
      " [0.73706239 0.26293761]\n",
      " [0.72251572 0.27748428]\n",
      " [0.81959324 0.18040676]\n",
      " [0.96764195 0.03235805]\n",
      " [0.82865513 0.17134487]\n",
      " [0.7256904  0.2743096 ]\n",
      " [0.74155594 0.25844406]\n",
      " [0.84421129 0.15578871]\n",
      " [0.93709909 0.06290091]\n",
      " [0.84691072 0.15308928]\n",
      " [0.84865863 0.15134137]\n",
      " [0.96329837 0.03670163]\n",
      " [0.85149116 0.14850884]\n",
      " [0.95871825 0.04128175]\n",
      " [0.96016955 0.03983045]\n",
      " [0.74604577 0.25395423]\n",
      " [0.71964609 0.28035391]\n",
      " [0.73245362 0.26754638]\n",
      " [0.97045076 0.02954924]\n",
      " [0.90134923 0.09865077]\n",
      " [0.81484529 0.18515471]\n",
      " [0.84321381 0.15678619]\n",
      " [0.65547856 0.34452144]\n",
      " [0.93293194 0.06706806]\n",
      " [0.80610609 0.19389391]\n",
      " [0.90033619 0.09966381]\n",
      " [0.97771062 0.02228938]\n",
      " [0.99379762 0.00620238]\n",
      " [0.87423701 0.12576299]\n",
      " [0.75726551 0.24273449]\n",
      " [0.8985466  0.1014534 ]\n",
      " [0.82676232 0.17323768]\n",
      " [0.85365786 0.14634214]\n",
      " [0.68691886 0.31308114]\n",
      " [0.9656063  0.0343937 ]\n",
      " [0.82162436 0.17837564]\n",
      " [0.83517449 0.16482551]\n",
      " [0.85073363 0.14926637]\n",
      " [0.75662327 0.24337673]\n",
      " [0.84225431 0.15774569]\n",
      " [0.94733125 0.05266875]\n",
      " [0.96981666 0.03018334]\n",
      " [0.90466907 0.09533093]\n",
      " [0.65977127 0.34022873]\n",
      " [0.89134265 0.10865735]\n",
      " [0.83857201 0.16142799]\n",
      " [0.93978721 0.06021279]\n",
      " [0.84655587 0.15344413]\n",
      " [0.77855988 0.22144012]\n",
      " [0.79373951 0.20626049]\n",
      " [0.8955407  0.1044593 ]\n",
      " [0.81479189 0.18520811]\n",
      " [0.78326994 0.21673006]\n",
      " [0.94929435 0.05070565]\n",
      " [0.9164704  0.0835296 ]\n",
      " [0.94494417 0.05505583]\n",
      " [0.87725982 0.12274018]\n",
      " [0.82158058 0.17841942]\n",
      " [0.80127842 0.19872158]\n",
      " [0.94498767 0.05501233]\n",
      " [0.83212327 0.16787673]\n",
      " [0.56339045 0.43660955]\n",
      " [0.85368644 0.14631356]\n",
      " [0.7920415  0.2079585 ]\n",
      " [0.87182793 0.12817207]\n",
      " [0.68801036 0.31198964]\n",
      " [0.92137534 0.07862466]\n",
      " [0.86315883 0.13684117]\n",
      " [0.89602115 0.10397885]\n",
      " [0.6024888  0.3975112 ]\n",
      " [0.81158235 0.18841765]\n",
      " [0.87039734 0.12960266]\n",
      " [0.81467282 0.18532718]\n",
      " [0.83692482 0.16307518]\n",
      " [0.82608082 0.17391918]\n",
      " [0.91273937 0.08726063]\n",
      " [0.81976167 0.18023833]\n",
      " [0.59559507 0.40440493]\n",
      " [0.89253295 0.10746705]\n",
      " [0.77700844 0.22299156]\n",
      " [0.93501729 0.06498271]\n",
      " [0.86015971 0.13984029]\n",
      " [0.78519706 0.21480294]\n",
      " [0.78037283 0.21962717]\n",
      " [0.66472896 0.33527104]\n",
      " [0.93933439 0.06066561]\n",
      " [0.72325309 0.27674691]\n",
      " [0.78515612 0.21484388]\n",
      " [0.7068661  0.2931339 ]\n",
      " [0.97854713 0.02145287]\n",
      " [0.82338898 0.17661102]\n",
      " [0.97064236 0.02935764]\n",
      " [0.77856555 0.22143445]\n",
      " [0.9565558  0.0434442 ]\n",
      " [0.97987778 0.02012222]\n",
      " [0.86269166 0.13730834]\n",
      " [0.91984252 0.08015748]\n",
      " [0.89250307 0.10749693]\n",
      " [0.90928571 0.09071429]\n",
      " [0.78854019 0.21145981]\n",
      " [0.91248557 0.08751443]\n",
      " [0.82593823 0.17406177]\n",
      " [0.93773473 0.06226527]\n",
      " [0.7564147  0.2435853 ]\n",
      " [0.90277967 0.09722033]\n",
      " [0.76601779 0.23398221]\n",
      " [0.87254921 0.12745079]\n",
      " [0.97200682 0.02799318]\n",
      " [0.96676843 0.03323157]\n",
      " [0.83909236 0.16090764]\n",
      " [0.54727643 0.45272357]\n",
      " [0.82330389 0.17669611]\n",
      " [0.7919678  0.2080322 ]\n",
      " [0.84132079 0.15867921]\n",
      " [0.95076399 0.04923601]\n",
      " [0.83319591 0.16680409]\n",
      " [0.87028449 0.12971551]\n",
      " [0.92246227 0.07753773]\n",
      " [0.84303122 0.15696878]\n",
      " [0.76926414 0.23073586]\n",
      " [0.78696044 0.21303956]\n",
      " [0.70882317 0.29117683]\n",
      " [0.89823473 0.10176527]\n",
      " [0.79750429 0.20249571]\n",
      " [0.89546468 0.10453532]\n",
      " [0.77840478 0.22159522]\n",
      " [0.85466581 0.14533419]\n",
      " [0.92565504 0.07434496]\n",
      " [0.98044035 0.01955965]\n",
      " [0.81144147 0.18855853]\n",
      " [0.84686928 0.15313072]\n",
      " [0.67773301 0.32226699]\n",
      " [0.94536845 0.05463155]\n",
      " [0.71001114 0.28998886]\n",
      " [0.82975375 0.17024625]\n",
      " [0.74203156 0.25796844]\n",
      " [0.65984678 0.34015322]\n",
      " [0.8077451  0.1922549 ]\n",
      " [0.69459888 0.30540112]\n",
      " [0.84371266 0.15628734]\n",
      " [0.90128852 0.09871148]\n",
      " [0.67127189 0.32872811]\n",
      " [0.93142847 0.06857153]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
    "\n",
    "df1 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.858696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.591146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.858696\n",
       "recall         0.229167\n",
       "precision      0.423077\n",
       "roc_auc_score  0.591146"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.35\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
    "\n",
    "df2 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.55625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "accuracy       0.87500\n",
       "recall         0.12500\n",
       "precision      0.60000\n",
       "roc_auc_score  0.55625"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.25\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
    "\n",
    "df3 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.817935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.327273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.629688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.817935\n",
       "recall         0.375000\n",
       "precision      0.327273\n",
       "roc_auc_score  0.629688"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.20\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
    "\n",
    "df4 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.733696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.669792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.733696\n",
       "recall         0.583333\n",
       "precision      0.264151\n",
       "roc_auc_score  0.669792"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
    "\n",
    "df5 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.631250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.543478\n",
       "recall         0.750000\n",
       "precision      0.187500\n",
       "roc_auc_score  0.631250"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.10\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > threshold, 1, 0)\n",
    "\n",
    "df6 = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.385870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.157692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.584896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.385870\n",
       "recall         0.854167\n",
       "precision      0.157692\n",
       "roc_auc_score  0.584896"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
